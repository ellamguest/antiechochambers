{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import TimeoutError\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\"\"\"BIG QUERY FUNCTIONS\"\"\"\n",
    "\n",
    "def client():\n",
    "    \"\"\"require a bigquery project and credentials, save in json in root main directory\"\"\"\n",
    "    credsfile = Path().resolve().joinpath('antiechochambers-1ba7f7f4c68e.json')\n",
    "    return bigquery.Client.from_service_account_json(credsfile)\n",
    "\n",
    "def jobConfig():\n",
    "    config = bigquery.QueryJobConfig()\n",
    "    config.query_parameters = (bigquery.ScalarQueryParameter('size', 'INT64', 10),)\n",
    "    config.use_legacy_sql = False\n",
    "    config.maximum_bytes_billed = int(5e9)\n",
    "    \n",
    "    return config\n",
    "\n",
    "def run_job(query):\n",
    "    print('Submitting query')\n",
    "    j = client().query(query=query, job_config=jobConfig())\n",
    "    with tqdm() as pbar:\n",
    "        while True:\n",
    "            try:\n",
    "                j.result(timeout=1)\n",
    "            except TimeoutError:                \n",
    "                pbar.update(1)\n",
    "            else:\n",
    "                break\n",
    "    return j\n",
    "\n",
    "def fetchQuery(query):\n",
    "    j = run_job(query)\n",
    "    df = j.to_dataframe()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fetchSubredditData(subreddit):\n",
    "    \"\"\"should create bot table to call on\"\"\"\n",
    "    query = f\"\"\"SELECT subreddit, author, COUNT(created_utc) as weight\n",
    "                FROM `fh-bigquery.reddit_comments.2017_06`\n",
    "                WHERE author in (SELECT author\n",
    "                                 FROM `aerobic-datum-126519.sms_18_sample_subreddits.mainSubInCounts`\n",
    "                                 WHERE (subreddit = '{subreddit}') AND (authorInCount > 2) AND\n",
    "                                         author not in (SELECT author\n",
    "                                                         FROM `fh-bigquery.reddit_comments.bots_201505`)\n",
    "                                        AND (lower(author) NOT LIKE '%bot%')\n",
    "                                        AND (author NOT LIKE 'JlmmyButler')\n",
    "                                        AND (author NOT LIKE 'TotesMessenger'))\n",
    "                GROUP BY subreddit, author\n",
    "                HAVING weight > 2\"\"\"\n",
    "\n",
    "    data = fetchQuery(query)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_node_ids_dict(edgelist):\n",
    "    node_ids = list(edgelist.subreddit.unique()) + list(edgelist.author.unique())\n",
    "    return dict(zip(node_ids, range(len(node_ids))))\n",
    "\n",
    "def get_edges(edgelist, subreddit):\n",
    "    node_ids_dict = get_node_ids_dict(edgelist)\n",
    "    start = time.time()\n",
    "    edgelist = edgelist[edgelist['subreddit']!=subreddit]\n",
    "    edges = pd.DataFrame({'subreddit':edgelist.subreddit.map(lambda x: node_ids_dict[x]),\n",
    "                          'author':edgelist.author.map(lambda x: node_ids_dict[x]),\n",
    "                          'weight':edgelist.weight})\n",
    "    edges = edges[['subreddit','author','weight']]\n",
    "    end = time.time()\n",
    "\n",
    "    elapsed = end-start\n",
    "    print(f'that took {elapsed} seconds')\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting unipartite network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "def project_unipartite_network(edgelist, subreddit, row='subreddit',col='author'):\n",
    "    edges = get_edges(edgelist, subreddit)\n",
    "    edges['value'] = 1\n",
    "    row_ind = np.array(edges[row])\n",
    "    col_ind = np.array(edges[col])\n",
    "    data = np.array(edges['value'], dtype=float)\n",
    "    mat_coo = sparse.coo_matrix((data, (row_ind, col_ind)))\n",
    "    mat_coo.sum_duplicates()\n",
    "    csr = mat_coo.tocsr()\n",
    "    #csr.sum_duplicates()\n",
    "\n",
    "    sub_net = csr.dot(csr.T).tolil()\n",
    "    sub_net.setdiag(0)\n",
    "    \n",
    "    return sub_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network density and degree histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_density(sub_net):\n",
    "    assert sub_net.shape[0]==sub_net.shape[1], 'matrix is not square'\n",
    "\n",
    "    N = sub_net.shape[0]\n",
    "    E = sub_net.getnnz()\n",
    "\n",
    "    return (E-N+1)/(N*(N-3)+2)\n",
    "    \n",
    "def get_degrees(network, network_type):\n",
    "    degrees = pd.DataFrame(np.count_nonzero(network.todense(), axis=1), columns=[f'{network_type}_degrees'])\n",
    "    weighted_degrees = pd.DataFrame(network.sum(axis=1),columns=[f'{network_type}_weighted_degrees'])\n",
    "    \n",
    "    return degrees, weighted_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_df(data, subreddit):\n",
    "    print('getting subreddit network...')\n",
    "    sub_net = project_unipartite_network(data, subreddit)\n",
    "    subreddit_density = get_network_density(sub_net)\n",
    "    #subreddit_degrees, subreddit_weighted_degrees = get_degrees(sub_net, 'subreddit')\n",
    "    \n",
    "    print('getting author network...')\n",
    "    author_net = project_unipartite_network(data, subreddit,row='author', col='subreddit')\n",
    "    author_density = get_network_density(author_net)\n",
    "    #author_degrees, author_weighted_degrees = get_degrees(author_net, 'author')\n",
    "\n",
    "    print('compiling stats...')\n",
    "    stats = {'sub_counts':data.subreddit.value_counts().describe(),\n",
    "             'author_counts':data.author.value_counts().describe(),\n",
    "             'bipartite_edge_weights':data.weight.describe(),\n",
    "             'sub_net_density':subreddit_density,\n",
    "             #'subreddit_degrees':subreddit_degrees['subreddit_degrees'].describe(),\n",
    "             #'subreddit_weighted_degrees':subreddit_weighted_degrees['subreddit_weighted_degrees'].describe(),\n",
    "             'author_net_density':author_density,\n",
    "             #'author_degrees':author_degrees['author_degrees'].describe(),\n",
    "             #'author_weighted_degrees':author_weighted_degrees['author_weighted_degrees'].describe()\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame.from_dict(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching data...\n",
      "Submitting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting subreddit network...\n",
      "that took 0.16529512405395508 seconds\n",
      "getting author network...\n",
      "that took 0.1575329303741455 seconds\n",
      "compiling stats...\n"
     ]
    }
   ],
   "source": [
    "td_data = fetchSubredditData(\"The_Donald\")\n",
    "td_stats_df = get_stats_df(td_data, \"The_Donald\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dfs = pd.concat([cmv_stats_df, td_stats_df],axis=0,keys=['cmv','td'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = lambda filename: Path().resolve().parent.joinpath(*['cache', filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dfs.to_csv('network_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting subreddit network...\n",
      "that took 0.04991888999938965 seconds\n",
      "getting author network...\n",
      "that took 0.050752878189086914 seconds\n",
      "compiling stats...\n"
     ]
    }
   ],
   "source": [
    "cmv_data = fetchSubredditData(\"changemyview\")\n",
    "cmv_stats_df = get_stats_df(cmv_data, \"changemyview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_counts</th>\n",
       "      <th>author_net_density</th>\n",
       "      <th>bipartite_edge_weights</th>\n",
       "      <th>sub_counts</th>\n",
       "      <th>sub_net_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3556.000000</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>32882.000000</td>\n",
       "      <td>4047.000000</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.246907</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>15.464662</td>\n",
       "      <td>8.125031</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.475191</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>42.176850</td>\n",
       "      <td>66.610722</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>2467.000000</td>\n",
       "      <td>3556.000000</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_counts  author_net_density  bipartite_edge_weights   sub_counts  \\\n",
       "count    3556.000000            0.059909            32882.000000  4047.000000   \n",
       "mean        9.246907            0.059909               15.464662     8.125031   \n",
       "std         9.475191            0.059909               42.176850    66.610722   \n",
       "min         1.000000            0.059909                3.000000     1.000000   \n",
       "25%         3.000000            0.059909                4.000000     1.000000   \n",
       "50%         6.000000            0.059909                6.000000     2.000000   \n",
       "75%        12.000000            0.059909               13.000000     4.000000   \n",
       "max        96.000000            0.059909             2467.000000  3556.000000   \n",
       "\n",
       "       sub_net_density  \n",
       "count         0.018425  \n",
       "mean          0.018425  \n",
       "std           0.018425  \n",
       "min           0.018425  \n",
       "25%           0.018425  \n",
       "50%           0.018425  \n",
       "75%           0.018425  \n",
       "max           0.018425  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmv_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropping weak ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "subreddit = \"changemyview\"\n",
    "data = fetchSubredditData(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>Kelsig</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>weedtese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>Feroc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>krimin_killr21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de</td>\n",
       "      <td>tastetherainbowmoth</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author  weight\n",
       "0        de               Kelsig       3\n",
       "1        de             weedtese       3\n",
       "2        de                Feroc       3\n",
       "3        de       krimin_killr21       3\n",
       "4        de  tastetherainbowmoth       4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(data, n=10, defaults=None):\n",
    "    sub_counts = data.subreddit.value_counts()\n",
    "    author_counts = data.author.value_counts()\n",
    "\n",
    "    keep_subs = sub_counts[sub_counts>=n].index\n",
    "    keep_authors = author_counts[author_counts>=n].index\n",
    "    \n",
    "    subset = data.copy()\n",
    "    \n",
    "    subset=subset[(subset['subreddit'].isin(keep_subs))&\n",
    "              (subset['author'].isin(keep_authors))&\n",
    "              (subset['weight']>=n)]\n",
    "    \n",
    "    if defaults:\n",
    "        subset=subset[~subset.isin(defaults)]\n",
    "    \n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmv_subset = get_subset(cmv_data, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6684, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmv_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting subreddit network...\n",
      "that took 0.014419078826904297 seconds\n",
      "getting author network...\n",
      "that took 0.032124996185302734 seconds\n",
      "compiling stats...\n"
     ]
    }
   ],
   "source": [
    "cmv_subset_stats = get_stats_df(cmv_subset, \"changemyview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_counts</th>\n",
       "      <th>author_net_density</th>\n",
       "      <th>bipartite_edge_weights</th>\n",
       "      <th>sub_counts</th>\n",
       "      <th>sub_net_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1186.000000</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>6684.000000</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.635750</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>36.471275</td>\n",
       "      <td>13.557809</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.341553</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>67.963827</td>\n",
       "      <td>42.663878</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>129.000000</td>\n",
       "      <td>0.197052</td>\n",
       "      <td>2467.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>0.149074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_counts  author_net_density  bipartite_edge_weights  sub_counts  \\\n",
       "count    1186.000000            0.197052             6684.000000  493.000000   \n",
       "mean        5.635750            0.197052               36.471275   13.557809   \n",
       "std         5.341553            0.197052               67.963827   42.663878   \n",
       "min         1.000000            0.197052               10.000000    1.000000   \n",
       "25%         3.000000            0.197052               13.000000    3.000000   \n",
       "50%         5.000000            0.197052               19.000000    5.000000   \n",
       "75%         7.000000            0.197052               35.000000   10.000000   \n",
       "max       129.000000            0.197052             2467.000000  600.000000   \n",
       "\n",
       "       sub_net_density  \n",
       "count         0.149074  \n",
       "mean          0.149074  \n",
       "std           0.149074  \n",
       "min           0.149074  \n",
       "25%           0.149074  \n",
       "50%           0.149074  \n",
       "75%           0.149074  \n",
       "max           0.149074  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmv_subset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "changemyview           505\n",
       "politics               293\n",
       "AskMen                  62\n",
       "Libertarian             62\n",
       "AdviceAnimals           60\n",
       "CringeAnarchy           54\n",
       "technology              52\n",
       "nba                     49\n",
       "NoStupidQuestions       44\n",
       "PoliticalDiscussion     42\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmv_subset.subreddit.value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "td_data = fetchSubredditData(\"The_Donald\")\n",
    "td_subset = get_subset(td_data, n=10, defaults=defaults_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130977, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting subreddit network...\n",
      "that took 0.036611080169677734 seconds\n",
      "getting author network...\n",
      "that took 0.025936126708984375 seconds\n",
      "compiling stats...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_counts</th>\n",
       "      <th>author_net_density</th>\n",
       "      <th>bipartite_edge_weights</th>\n",
       "      <th>sub_counts</th>\n",
       "      <th>sub_net_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3416.000000</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>18173.000000</td>\n",
       "      <td>1123.000000</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.319965</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>39.539757</td>\n",
       "      <td>16.182547</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.758141</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>74.024180</td>\n",
       "      <td>82.809176</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.132256</td>\n",
       "      <td>2467.000000</td>\n",
       "      <td>2135.000000</td>\n",
       "      <td>0.060784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_counts  author_net_density  bipartite_edge_weights   sub_counts  \\\n",
       "count    3416.000000            0.132256            18173.000000  1123.000000   \n",
       "mean        5.319965            0.132256               39.539757    16.182547   \n",
       "std         4.758141            0.132256               74.024180    82.809176   \n",
       "min         1.000000            0.132256               10.000000     1.000000   \n",
       "25%         3.000000            0.132256               13.000000     2.000000   \n",
       "50%         4.000000            0.132256               19.000000     4.000000   \n",
       "75%         7.000000            0.132256               36.000000     9.000000   \n",
       "max       175.000000            0.132256             2467.000000  2135.000000   \n",
       "\n",
       "       sub_net_density  \n",
       "count         0.060784  \n",
       "mean          0.060784  \n",
       "std           0.060784  \n",
       "min           0.060784  \n",
       "25%           0.060784  \n",
       "50%           0.060784  \n",
       "75%           0.060784  \n",
       "max           0.060784  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_subset_stats = get_stats_df(td_subset, \"The_Donald\")\n",
    "td_subset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The_Donald        2135\n",
       "politics           723\n",
       "CringeAnarchy      265\n",
       "nba                196\n",
       "conspiracy         182\n",
       "KotakuInAction     160\n",
       "AdviceAnimals      141\n",
       "pcmasterrace       128\n",
       "Conservative       107\n",
       "PoliticalHumor     103\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_subset.subreddit.value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = \"\"\"\n",
    "/r/announcements/\n",
    "/r/Art/\n",
    "/r/AskReddit/\n",
    "/r/askscience/\n",
    "/r/aww/\n",
    "/r/blog/\n",
    "/r/books/\n",
    "/r/creepy/\n",
    "/r/dataisbeautiful/\n",
    "/r/DIY/\n",
    "/r/Documentaries/\n",
    "/r/EarthPorn/\n",
    "/r/explainlikeimfive/\n",
    "/r/food/\n",
    "/r/funny/\n",
    "/r/Futurology/\n",
    "/r/gadgets/\n",
    "/r/gaming/\n",
    "/r/GetMotivated/\n",
    "/r/gifs/\n",
    "/r/history/\n",
    "/r/IAmA/\n",
    "/r/InternetIsBeautiful/\n",
    "/r/Jokes/\n",
    "/r/LifeProTips/\n",
    "/r/listentothis/\n",
    "/r/mildlyinteresting/\n",
    "/r/movies/\n",
    "/r/Music/\n",
    "/r/news/\n",
    "/r/nosleep/\n",
    "/r/nottheonion/\n",
    "/r/OldSchoolCool/\n",
    "/r/personalfinance/\n",
    "/r/philosophy/\n",
    "/r/photoshopbattles/\n",
    "/r/pics/\n",
    "/r/science/\n",
    "/r/Showerthoughts/\n",
    "/r/space/\n",
    "/r/sports/\n",
    "/r/television/\n",
    "/r/tifu/\n",
    "/r/todayilearned/\n",
    "/r/UpliftingNews/\n",
    "/r/videos/\n",
    "/r/worldnews/\n",
    "\"\"\"\n",
    "\n",
    "defaults_list = [x.strip('/\\n') for x in defaults.split('/r/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmv_subset = get_subset(cmv_data, n=10, defaults=defaults_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def fetchSubList():\n",
    "    \"\"\"should create bot table to call on\"\"\"\n",
    "    query = f\"\"\"SELECT *\n",
    "                 FROM `aerobic-datum-126519.sms_18_sample_subreddits.randomSubreddits`\n",
    "                 \"\"\"\n",
    "\n",
    "    data = fetchQuery(query)\n",
    "    \n",
    "    return data\n",
    "\n",
    "sublist = fetchSubList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subAuthorCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>heat</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Gonewild18</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>SoccerBetting</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>DIY_eJuice</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Judaism</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>finance</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>bikewrench</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Foofighters</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>RelayForReddit</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  subAuthorCount\n",
       "900            heat            1000\n",
       "901      Gonewild18            1000\n",
       "911          Eminem            1002\n",
       "919   SoccerBetting            1004\n",
       "918      DIY_eJuice            1004\n",
       "920         Judaism            1004\n",
       "928         finance            1006\n",
       "936      bikewrench            1008\n",
       "943     Foofighters            1010\n",
       "948  RelayForReddit            1011"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublist.sort_values('subAuthorCount').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subAuthorCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>me_irl</td>\n",
       "      <td>31132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>xboxone</td>\n",
       "      <td>31141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>nfl</td>\n",
       "      <td>32821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>PUBATTLEGROUNDS</td>\n",
       "      <td>33686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Futurology</td>\n",
       "      <td>33922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>relationships</td>\n",
       "      <td>34025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Games</td>\n",
       "      <td>35113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td>38533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Music</td>\n",
       "      <td>39044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>39071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>41373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Jokes</td>\n",
       "      <td>42528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>soccer</td>\n",
       "      <td>45578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>52717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>53794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>television</td>\n",
       "      <td>55325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>OldSchoolCool</td>\n",
       "      <td>56333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>WTF</td>\n",
       "      <td>69993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>101370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>gifs</td>\n",
       "      <td>125891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit  subAuthorCount\n",
       "627              me_irl           31132\n",
       "663             xboxone           31141\n",
       "228                 nfl           32821\n",
       "597     PUBATTLEGROUNDS           33686\n",
       "527          Futurology           33922\n",
       "910       relationships           34025\n",
       "181               Games           35113\n",
       "538   interestingasfuck           38533\n",
       "534               Music           39044\n",
       "642   explainlikeimfive           39071\n",
       "634  BlackPeopleTwitter           41373\n",
       "141               Jokes           42528\n",
       "50               soccer           45578\n",
       "927         LifeProTips           52717\n",
       "150       AdviceAnimals           53794\n",
       "129          television           55325\n",
       "65        OldSchoolCool           56333\n",
       "438                 WTF           69993\n",
       "981      Showerthoughts          101370\n",
       "764                gifs          125891"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublist.sort_values('subAuthorCount').tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1000.000000\n",
       "mean       4671.660000\n",
       "std        8382.077886\n",
       "min        1000.000000\n",
       "25%        1368.000000\n",
       "50%        2227.000000\n",
       "75%        4448.500000\n",
       "max      125891.000000\n",
       "Name: subAuthorCount, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublist.subAuthorCount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchSubredditData(subreddit):\n",
    "    \"\"\"should create bot table to call on\"\"\"\n",
    "    query = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM `aerobic-datum-126519.sms_18_sample_subreddits.allAuthorCommentCounts`\n",
    "                WHERE author in (SELECT author\n",
    "                                 FROM `aerobic-datum-126519.sms_18_sample_subreddits.randomSubredditAuthors`\n",
    "                                 WHERE (subreddit = '{subreddit}') AND (authorInCOunt > 2) AND\n",
    "                                         author not in (SELECT author\n",
    "                                                         FROM `fh-bigquery.reddit_comments.bots_201505`)\n",
    "                                        AND (lower(author) NOT LIKE '%bot%')\n",
    "                                        AND (author NOT LIKE 'JlmmyButler')\n",
    "                                        AND (author NOT LIKE 'TotesMessenger'))\n",
    "                    AND authorCommentCount > 2\n",
    "                ORDER BY subreddit, author\n",
    "                \"\"\"\n",
    "\n",
    "    data = fetchQuery(query)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1720, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit = \"finance\"\n",
    "data = fetchSubredditData(subreddit)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007scape</td>\n",
       "      <td>Jjtardiff</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007scape</td>\n",
       "      <td>smallatom</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3Dprinting</td>\n",
       "      <td>Godspiral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49ers</td>\n",
       "      <td>twoambien</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCDesis</td>\n",
       "      <td>get_real_quick</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit          author  weight\n",
       "0   2007scape       Jjtardiff      28\n",
       "1   2007scape       smallatom       4\n",
       "2  3Dprinting       Godspiral       4\n",
       "3       49ers       twoambien       5\n",
       "4    ABCDesis  get_real_quick       6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['subreddit','author','weight']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting subreddit network...\n",
      "that took 0.008287191390991211 seconds\n",
      "getting author network...\n",
      "that took 0.004868030548095703 seconds\n",
      "compiling stats...\n"
     ]
    }
   ],
   "source": [
    "stats_df = get_stats_df(data, subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_counts</th>\n",
       "      <th>author_net_density</th>\n",
       "      <th>bipartite_edge_weights</th>\n",
       "      <th>sub_counts</th>\n",
       "      <th>sub_net_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>1720.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.610619</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>13.008721</td>\n",
       "      <td>2.548148</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.544162</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>32.126720</td>\n",
       "      <td>9.562320</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_counts  author_net_density  bipartite_edge_weights  sub_counts  \\\n",
       "count     226.000000            0.010028             1720.000000  675.000000   \n",
       "mean        7.610619            0.010028               13.008721    2.548148   \n",
       "std         7.544162            0.010028               32.126720    9.562320   \n",
       "min         1.000000            0.010028                3.000000    1.000000   \n",
       "25%         2.000000            0.010028                3.000000    1.000000   \n",
       "50%         5.500000            0.010028                5.000000    1.000000   \n",
       "75%        10.000000            0.010028               11.000000    2.000000   \n",
       "max        53.000000            0.010028              579.000000  226.000000   \n",
       "\n",
       "       sub_net_density  \n",
       "count         0.038756  \n",
       "mean          0.038756  \n",
       "std           0.038756  \n",
       "min           0.038756  \n",
       "25%           0.038756  \n",
       "50%           0.038756  \n",
       "75%           0.038756  \n",
       "max           0.038756  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
